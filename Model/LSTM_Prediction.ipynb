{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580cd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c95f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Code</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>11.40</td>\n",
       "      <td>9.04</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.25</td>\n",
       "      <td>6.54</td>\n",
       "      <td>...</td>\n",
       "      <td>8.54</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.33</td>\n",
       "      <td>8.94</td>\n",
       "      <td>9.05</td>\n",
       "      <td>9.54</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.33</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>96.00</td>\n",
       "      <td>94.87</td>\n",
       "      <td>94.50</td>\n",
       "      <td>102.03</td>\n",
       "      <td>99.78</td>\n",
       "      <td>103.99</td>\n",
       "      <td>105.30</td>\n",
       "      <td>109.39</td>\n",
       "      <td>...</td>\n",
       "      <td>156.40</td>\n",
       "      <td>166.21</td>\n",
       "      <td>167.32</td>\n",
       "      <td>179.68</td>\n",
       "      <td>189.89</td>\n",
       "      <td>193.59</td>\n",
       "      <td>203.79</td>\n",
       "      <td>211.66</td>\n",
       "      <td>209.41</td>\n",
       "      <td>211.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>150.61</td>\n",
       "      <td>151.28</td>\n",
       "      <td>151.61</td>\n",
       "      <td>152.39</td>\n",
       "      <td>152.54</td>\n",
       "      <td>156.90</td>\n",
       "      <td>161.39</td>\n",
       "      <td>156.01</td>\n",
       "      <td>...</td>\n",
       "      <td>173.99</td>\n",
       "      <td>180.66</td>\n",
       "      <td>186.83</td>\n",
       "      <td>220.92</td>\n",
       "      <td>185.95</td>\n",
       "      <td>203.34</td>\n",
       "      <td>185.10</td>\n",
       "      <td>207.66</td>\n",
       "      <td>182.19</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>323.84</td>\n",
       "      <td>328.83</td>\n",
       "      <td>333.22</td>\n",
       "      <td>335.73</td>\n",
       "      <td>340.81</td>\n",
       "      <td>341.39</td>\n",
       "      <td>344.46</td>\n",
       "      <td>346.24</td>\n",
       "      <td>...</td>\n",
       "      <td>468.33</td>\n",
       "      <td>452.69</td>\n",
       "      <td>440.34</td>\n",
       "      <td>450.10</td>\n",
       "      <td>464.88</td>\n",
       "      <td>462.89</td>\n",
       "      <td>456.74</td>\n",
       "      <td>460.21</td>\n",
       "      <td>469.73</td>\n",
       "      <td>469.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>VUT</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>VEN</td>\n",
       "      <td>303.14</td>\n",
       "      <td>304.92</td>\n",
       "      <td>308.93</td>\n",
       "      <td>315.26</td>\n",
       "      <td>318.02</td>\n",
       "      <td>326.54</td>\n",
       "      <td>331.00</td>\n",
       "      <td>337.59</td>\n",
       "      <td>...</td>\n",
       "      <td>265.49</td>\n",
       "      <td>261.47</td>\n",
       "      <td>291.82</td>\n",
       "      <td>323.30</td>\n",
       "      <td>343.49</td>\n",
       "      <td>373.61</td>\n",
       "      <td>359.46</td>\n",
       "      <td>352.14</td>\n",
       "      <td>352.08</td>\n",
       "      <td>338.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>VNM</td>\n",
       "      <td>25.63</td>\n",
       "      <td>28.49</td>\n",
       "      <td>31.00</td>\n",
       "      <td>37.69</td>\n",
       "      <td>43.31</td>\n",
       "      <td>49.46</td>\n",
       "      <td>56.03</td>\n",
       "      <td>63.80</td>\n",
       "      <td>...</td>\n",
       "      <td>209.45</td>\n",
       "      <td>231.71</td>\n",
       "      <td>251.16</td>\n",
       "      <td>235.76</td>\n",
       "      <td>237.24</td>\n",
       "      <td>249.25</td>\n",
       "      <td>263.12</td>\n",
       "      <td>306.26</td>\n",
       "      <td>320.67</td>\n",
       "      <td>319.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>485.43</td>\n",
       "      <td>484.96</td>\n",
       "      <td>484.28</td>\n",
       "      <td>483.00</td>\n",
       "      <td>481.44</td>\n",
       "      <td>478.95</td>\n",
       "      <td>444.46</td>\n",
       "      <td>405.54</td>\n",
       "      <td>...</td>\n",
       "      <td>471.05</td>\n",
       "      <td>412.65</td>\n",
       "      <td>460.49</td>\n",
       "      <td>432.46</td>\n",
       "      <td>455.21</td>\n",
       "      <td>468.32</td>\n",
       "      <td>440.83</td>\n",
       "      <td>473.30</td>\n",
       "      <td>495.17</td>\n",
       "      <td>495.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>71.10</td>\n",
       "      <td>71.40</td>\n",
       "      <td>72.21</td>\n",
       "      <td>68.67</td>\n",
       "      <td>68.41</td>\n",
       "      <td>68.26</td>\n",
       "      <td>69.62</td>\n",
       "      <td>68.79</td>\n",
       "      <td>...</td>\n",
       "      <td>62.83</td>\n",
       "      <td>63.73</td>\n",
       "      <td>66.75</td>\n",
       "      <td>67.43</td>\n",
       "      <td>67.68</td>\n",
       "      <td>67.64</td>\n",
       "      <td>66.25</td>\n",
       "      <td>67.59</td>\n",
       "      <td>66.16</td>\n",
       "      <td>66.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Country Code    1990    1991    1992    1993    1994    1995  \\\n",
       "0                Albania  ALB   11.40    9.04    6.99    6.93    7.77    7.53   \n",
       "1                Algeria  DZA   96.00   94.87   94.50  102.03   99.78  103.99   \n",
       "2                 Angola  AGO  150.61  151.28  151.61  152.39  152.54  156.90   \n",
       "3    Antigua and Barbuda  ATG    0.34    0.35    0.43    0.41    0.42    0.44   \n",
       "4              Argentina  ARG  323.84  328.83  333.22  335.73  340.81  341.39   \n",
       "..                   ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "162              Vanuatu  VUT    0.47    0.48    0.50    0.53    0.54    0.54   \n",
       "163            Venezuela  VEN  303.14  304.92  308.93  315.26  318.02  326.54   \n",
       "164              Vietnam  VNM   25.63   28.49   31.00   37.69   43.31   49.46   \n",
       "165               Zambia  ZMB  485.43  484.96  484.28  483.00  481.44  478.95   \n",
       "166             Zimbabwe  ZWE   71.10   71.40   72.21   68.67   68.41   68.26   \n",
       "\n",
       "       1996    1997  ...    2008    2009    2010    2011    2012    2013  \\\n",
       "0      7.25    6.54  ...    8.54    8.60    8.88    9.33    8.94    9.05   \n",
       "1    105.30  109.39  ...  156.40  166.21  167.32  179.68  189.89  193.59   \n",
       "2    161.39  156.01  ...  173.99  180.66  186.83  220.92  185.95  203.34   \n",
       "3      0.47    0.50  ...    1.06    2.02    1.13    1.07    1.29    1.06   \n",
       "4    344.46  346.24  ...  468.33  452.69  440.34  450.10  464.88  462.89   \n",
       "..      ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "162    0.57    0.57  ...    0.70    0.70    0.71    0.75    0.75    0.75   \n",
       "163  331.00  337.59  ...  265.49  261.47  291.82  323.30  343.49  373.61   \n",
       "164   56.03   63.80  ...  209.45  231.71  251.16  235.76  237.24  249.25   \n",
       "165  444.46  405.54  ...  471.05  412.65  460.49  432.46  455.21  468.32   \n",
       "166   69.62   68.79  ...   62.83   63.73   66.75   67.43   67.68   67.64   \n",
       "\n",
       "       2014    2015    2016    2017  \n",
       "0      9.54    9.48    9.33    9.90  \n",
       "1    203.79  211.66  209.41  211.50  \n",
       "2    185.10  207.66  182.19  176.85  \n",
       "3      1.08    1.10    1.14    1.17  \n",
       "4    456.74  460.21  469.73  469.62  \n",
       "..      ...     ...     ...     ...  \n",
       "162    0.81    0.81    0.84    0.84  \n",
       "163  359.46  352.14  352.08  338.14  \n",
       "164  263.12  306.26  320.67  319.54  \n",
       "165  440.83  473.30  495.17  495.99  \n",
       "166   66.25   67.59   66.16   66.53  \n",
       "\n",
       "[167 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://raw.githubusercontent.com/FabioHodo/EIB2_ClimateRisk/main/cleaned%20data/data_imputed/imputed_knn/'\n",
    "df = pd.read_csv(path +'Emissions_GHG_(fromCAIT).csv',index_col='Unnamed: 0' )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0cc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMonthly(country, scale = 20):\n",
    "    '''\n",
    "    Turn the yearly data into monthly using Brownian bridge algorithm\n",
    "    Parameter:\n",
    "        country: a string for the country name\n",
    "        scale: an integer for the data scaling\n",
    "    Return:\n",
    "        the scaled monthly data\n",
    "    '''\n",
    "    \n",
    "    AnnualVal = country*scale\n",
    "    n = (len(AnnualVal)-1)*12\n",
    "    monthly = np.zeros(n+1)\n",
    "    monthlyVal = np.zeros(n)\n",
    "    for i in range(1, len(AnnualVal)+1):\n",
    "        monthly[(i-1)*12] = AnnualVal[i-1]\n",
    "\n",
    "    for i in range(1, len(AnnualVal)): #1-4\n",
    "        for j in range ((i-1)*12+1, (i)*12): #0 to  47\n",
    "            monthly[j] = monthly[j-1] + (monthly[(i)*12] - monthly[j-1])*(1/((i*12)-(j-1)))\n",
    "            + (((i*12-j)*(1)/(i*12-(j-1)))**(1/2))*np.random.randn()\n",
    "            monthlyVal[j-1] = monthly[j] -monthly[j-1]\n",
    "    return monthly/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b63990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset,timestep = 6):\n",
    "    data_x,data_y = [],[]\n",
    "    for i in range(len(dataset)-timestep-1):\n",
    "        a = dataset[i:i+timestep,0]\n",
    "        data_x.append(a)\n",
    "        data_y.append(dataset[i+timestep,0])\n",
    "    return np.array(data_x),np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aa3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(num_prediction, model, test_data, look_back):\n",
    "    prediction_list = test_data[-look_back:]\n",
    "    \n",
    "    for i in range(num_prediction):\n",
    "        x = prediction_list[-look_back:]\n",
    "        #print(x)\n",
    "        x = x.reshape((1, look_back, 1))\n",
    "        out = model.predict(x)[0][0]\n",
    "        prediction_list = np.append(prediction_list, out)\n",
    "    prediction_list = prediction_list[look_back:]\n",
    "        \n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3f8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FuturePrediction(country,look_back,num_prediction):\n",
    "    '''\n",
    "    Make prediction for the data of one country to 2030\n",
    "    Parameter:\n",
    "        country: a string that specifies the country name\n",
    "    Return:\n",
    "        prediction: a list of values for future prediction of the data for each year\n",
    "    '''\n",
    "    data = df[df['Country']==country]\n",
    "    data = data.loc[:,\"1990\":\"2017\"].T\n",
    "    monthly = makeMonthly(np.array(data), 10)\n",
    "    monthly = np.reshape(monthly, (-1, 1))\n",
    "    \n",
    "    # Feature Scaling\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(monthly)\n",
    "    \n",
    "    #split train and test dataset\n",
    "    train_size = int(len(data)*0.7)\n",
    "    test_size = len(data)-train_size\n",
    "    train_data, test_data = data[0:train_size,:],data[train_size:len(data),:]\n",
    "    \n",
    "    x_train, y_train = create_dataset(train_data,timestep = look_back)\n",
    "    x_test, y_test = create_dataset(test_data,timestep = look_back)\n",
    "    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "    \n",
    "    # Create the Stacked LSTM model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    # Fitting the RNN to the Training set\n",
    "    model.fit(x_train, y_train, validation_data = (x_test, y_test) ,epochs = 20, batch_size = 10,verbose =1,\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "    \n",
    "    # Make monthly predictions into the future\n",
    "    x = predict(num_prediction, model, test_data, look_back)\n",
    "    prediction = scaler.inverse_transform(x.reshape(-1,1))\n",
    "    # Make yearly predictions into the future\n",
    "    annual_prediction = prediction[11:num_prediction:12]\n",
    "    return annual_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800285ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictAll(df,look_back,num_prediction):\n",
    "    '''\n",
    "    Make predictions to 2030 for all the countries with valid data\n",
    "    Parameter:\n",
    "        df: a dataframe with the data\n",
    "    Return:\n",
    "        df: a dataframe with the original data and the predictions\n",
    "    '''\n",
    "    countries = df['Country']\n",
    "    world_prediction = []\n",
    "    for country in countries:\n",
    "        #print(FuturePrediction(country,look_back,num_prediction))\n",
    "        world_prediction.append(FuturePrediction(country,look_back,num_prediction))\n",
    "    world_prediction = np.squeeze(np.array(world_prediction), axis = (2,))\n",
    "    years = ['2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030']\n",
    "    #print(world_prediction)\n",
    "    #print(world_prediction.shape)\n",
    "    #print(world_prediction[:, 1])\n",
    "    for i in range(len(years)):\n",
    "        df[years[i]] = world_prediction[:, i]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc643230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1ef6d6663d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mghg_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mghg_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-2e4cef30889d>\u001b[0m in \u001b[0;36mPredictAll\u001b[0;34m(df, look_back, num_prediction)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(FuturePrediction(country,look_back,num_prediction))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mworld_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFuturePrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mworld_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2018'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2019'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2020'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2021'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2022'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2023'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2024'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2025'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2026'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2027'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2028'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2029'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2030'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-aabad634ce4d>\u001b[0m in \u001b[0;36mFuturePrediction\u001b[0;34m(country, look_back, num_prediction)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Fitting the RNN to the Training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     model.fit(x_train, y_train, validation_data = (x_test, y_test) ,epochs = 50, batch_size = 10,verbose =1,\n\u001b[0m\u001b[1;32m     49\u001b[0m          callbacks=[EarlyStopping(monitor='val_loss', patience=10)], shuffle=False)\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ghg_prediction = PredictAll(df,look_back=5,num_prediction=13*12)\n",
    "ghg_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset as csv for model fitting later\n",
    "ghg_prediction.to_csv(\"GHG emission to 2030 (LSTM).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdff35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
