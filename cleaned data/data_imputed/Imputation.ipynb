{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: For Emissions: \"\" and -- means missing\n",
    "# For Energy_Use, \"\" is missing, For Energy_consumption -- means missing\n",
    "# For Fossil_fuel_Energy both 0 and \"\" mean missing, can actually omit this and use renewable_energy instead (too much missing data)\n",
    "#for GDP and Population -- means missing\n",
    "# For Renewable_energy_cons \"\" means missing\n",
    "# for Rents \"\" missing\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import missingno as mno\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data and keep only those whose ISO matches all the datasets\n",
    "countries = pd.read_excel(\"./countries.xlsx\")\n",
    "\n",
    "def getData(file):\n",
    "    data = pd.read_csv(file, skiprows=1)\n",
    "    \n",
    "    data[\"Country\"]=data[\"Country\"].apply(lambda x: x.strip()) #strip trailing spaces\n",
    "    data = data[data[\"Code\"].isin(countries[\"Code\"])] # check to see if it is in list\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions_Coal.csv\n",
      "Emissions_GHG_(fromCAIT).csv\n",
      "Emissions_Natural_Gas.csv\n",
      "Emissions_Petroleum_other.csv\n",
      "Emissions_Total.csv\n",
      "Energy_Consumption_per_Capita.csv\n",
      "Energy_consumption_per_GDP.csv\n",
      "Energy_use(kg-of-oil-equivalent-per-capita).csv\n",
      "Fossil_fuel_energy_consumption(%_of_total).csv\n",
      "GDP.csv\n",
      "Population.csv\n",
      "Renewable_energy_consumption(%_of_total_final_energy_consumption).csv\n",
      "Rents_Coal.csv\n",
      "Rents_NaturalGas.csv\n",
      "Rents_Oil.csv\n"
     ]
    }
   ],
   "source": [
    "#Process all files and add them to a list of dataframes for easy manipulation\n",
    "\n",
    "df_list = []\n",
    "df_names = []\n",
    "for filename in os.listdir(\"data_processed/\"):\n",
    "    #print(filename)\n",
    "    path = \"data_processed/\" + filename\n",
    "    df_list.append(getData(path))\n",
    "    df_names.append(filename)\n",
    "\n",
    "for i in range(15):\n",
    "    #print(df_list[i].shape)\n",
    "    print(df_names[i])\n",
    "\n",
    "#mno.matrix(df_list[7], figsize = (10, 3))\n",
    "#mno.matrix(df_list[8], figsize = (10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNimpute(dataframe):\n",
    "    temp = dataframe\n",
    "    temp = temp.drop(columns=['Code','Country'])\n",
    "    temp = temp.transpose()\n",
    "\n",
    "    temp = temp.replace('', np.NaN)\n",
    "    temp = temp.replace('--', np.NaN)\n",
    "     \n",
    "    #impute\n",
    "    imputer = KNNImputer(n_neighbors = 3)\n",
    "    temp = pd.DataFrame(imputer.fit_transform(temp))\n",
    "    \n",
    "    #transpose back and add columns names and index back\n",
    "    temp = temp.transpose()\n",
    "    temp.insert(0,'c1',dataframe.Country)\n",
    "    temp.insert(1,'c2',dataframe.Code)\n",
    "    temp.columns = dataframe.columns\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Code</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>3.130703</td>\n",
       "      <td>1.779817</td>\n",
       "      <td>0.502372</td>\n",
       "      <td>0.332177</td>\n",
       "      <td>0.269835</td>\n",
       "      <td>0.205073</td>\n",
       "      <td>0.161310</td>\n",
       "      <td>0.119023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329973</td>\n",
       "      <td>0.309336</td>\n",
       "      <td>0.277316</td>\n",
       "      <td>0.246716</td>\n",
       "      <td>0.311598</td>\n",
       "      <td>0.264177</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>0.204719</td>\n",
       "      <td>0.204280</td>\n",
       "      <td>0.234532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>3.136276</td>\n",
       "      <td>2.898887</td>\n",
       "      <td>2.687475</td>\n",
       "      <td>2.110768</td>\n",
       "      <td>2.150592</td>\n",
       "      <td>1.284432</td>\n",
       "      <td>1.443130</td>\n",
       "      <td>1.537015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099877</td>\n",
       "      <td>1.407936</td>\n",
       "      <td>1.388799</td>\n",
       "      <td>0.982267</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>0.513685</td>\n",
       "      <td>0.396965</td>\n",
       "      <td>0.410189</td>\n",
       "      <td>0.232647</td>\n",
       "      <td>0.352335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>3.373197</td>\n",
       "      <td>2.903367</td>\n",
       "      <td>2.906775</td>\n",
       "      <td>2.671719</td>\n",
       "      <td>3.631131</td>\n",
       "      <td>3.278262</td>\n",
       "      <td>3.042341</td>\n",
       "      <td>2.907947</td>\n",
       "      <td>...</td>\n",
       "      <td>3.664644</td>\n",
       "      <td>3.937608</td>\n",
       "      <td>4.320512</td>\n",
       "      <td>4.357923</td>\n",
       "      <td>4.120342</td>\n",
       "      <td>3.856025</td>\n",
       "      <td>3.725291</td>\n",
       "      <td>3.656726</td>\n",
       "      <td>3.053126</td>\n",
       "      <td>1.974290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>0.220518</td>\n",
       "      <td>0.164039</td>\n",
       "      <td>0.351333</td>\n",
       "      <td>0.220518</td>\n",
       "      <td>0.089702</td>\n",
       "      <td>0.051080</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.011523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Australia</td>\n",
       "      <td>AUS</td>\n",
       "      <td>155.822075</td>\n",
       "      <td>158.441840</td>\n",
       "      <td>162.299485</td>\n",
       "      <td>157.161279</td>\n",
       "      <td>157.663172</td>\n",
       "      <td>164.275304</td>\n",
       "      <td>175.733781</td>\n",
       "      <td>180.658842</td>\n",
       "      <td>...</td>\n",
       "      <td>193.453158</td>\n",
       "      <td>184.804494</td>\n",
       "      <td>180.995687</td>\n",
       "      <td>168.465633</td>\n",
       "      <td>160.055324</td>\n",
       "      <td>167.850923</td>\n",
       "      <td>166.152335</td>\n",
       "      <td>160.700259</td>\n",
       "      <td>146.703499</td>\n",
       "      <td>141.675568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>14.127443</td>\n",
       "      <td>15.232404</td>\n",
       "      <td>10.807675</td>\n",
       "      <td>9.358016</td>\n",
       "      <td>9.760491</td>\n",
       "      <td>11.893954</td>\n",
       "      <td>12.516650</td>\n",
       "      <td>12.795775</td>\n",
       "      <td>...</td>\n",
       "      <td>12.262878</td>\n",
       "      <td>12.373503</td>\n",
       "      <td>11.797346</td>\n",
       "      <td>12.090293</td>\n",
       "      <td>11.263249</td>\n",
       "      <td>12.029014</td>\n",
       "      <td>11.297731</td>\n",
       "      <td>11.916427</td>\n",
       "      <td>10.410354</td>\n",
       "      <td>11.069428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>AZE</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.026736</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.029498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>BHR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>0.172274</td>\n",
       "      <td>0.153526</td>\n",
       "      <td>0.336537</td>\n",
       "      <td>0.405456</td>\n",
       "      <td>0.475294</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>0.612108</td>\n",
       "      <td>0.893869</td>\n",
       "      <td>...</td>\n",
       "      <td>4.564487</td>\n",
       "      <td>4.677082</td>\n",
       "      <td>4.721276</td>\n",
       "      <td>4.856450</td>\n",
       "      <td>4.966350</td>\n",
       "      <td>7.455797</td>\n",
       "      <td>6.574876</td>\n",
       "      <td>7.867665</td>\n",
       "      <td>10.029381</td>\n",
       "      <td>16.538289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>BRB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>BLR</td>\n",
       "      <td>1.675367</td>\n",
       "      <td>1.664689</td>\n",
       "      <td>1.753269</td>\n",
       "      <td>1.735387</td>\n",
       "      <td>1.537446</td>\n",
       "      <td>1.703351</td>\n",
       "      <td>1.748451</td>\n",
       "      <td>1.571995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440235</td>\n",
       "      <td>0.492009</td>\n",
       "      <td>1.157398</td>\n",
       "      <td>1.573173</td>\n",
       "      <td>2.003347</td>\n",
       "      <td>1.785506</td>\n",
       "      <td>1.534337</td>\n",
       "      <td>1.630996</td>\n",
       "      <td>1.625882</td>\n",
       "      <td>1.776002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>41.826680</td>\n",
       "      <td>40.069733</td>\n",
       "      <td>36.180079</td>\n",
       "      <td>33.563478</td>\n",
       "      <td>36.907566</td>\n",
       "      <td>35.683791</td>\n",
       "      <td>33.237015</td>\n",
       "      <td>30.462139</td>\n",
       "      <td>...</td>\n",
       "      <td>13.256519</td>\n",
       "      <td>12.704695</td>\n",
       "      <td>11.926863</td>\n",
       "      <td>12.603332</td>\n",
       "      <td>11.299655</td>\n",
       "      <td>10.555315</td>\n",
       "      <td>9.940550</td>\n",
       "      <td>9.656882</td>\n",
       "      <td>9.914315</td>\n",
       "      <td>10.184480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Belize</td>\n",
       "      <td>BLZ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country Code        1990        1991        1992        1993  \\\n",
       "0               Albania  ALB    3.130703    1.779817    0.502372    0.332177   \n",
       "1               Algeria  DZA    3.136276    2.898887    2.687475    2.110768   \n",
       "2                Angola  AGO    0.000000    0.000000    0.000000    0.000000   \n",
       "3   Antigua and Barbuda  ATG    0.000000    0.000000    0.000000    0.000000   \n",
       "4             Argentina  ARG    3.373197    2.903367    2.906775    2.671719   \n",
       "5               Armenia  ARM    0.220518    0.164039    0.351333    0.220518   \n",
       "6             Australia  AUS  155.822075  158.441840  162.299485  157.161279   \n",
       "7               Austria  AUT   14.127443   15.232404   10.807675    9.358016   \n",
       "8            Azerbaijan  AZE    0.025163    0.026736    0.063694    0.009436   \n",
       "9               Bahrain  BHR    0.000000    0.000000    0.000000    0.000000   \n",
       "10           Bangladesh  BGD    0.172274    0.153526    0.336537    0.405456   \n",
       "11             Barbados  BRB    0.000000    0.000000    0.000000    0.000000   \n",
       "12              Belarus  BLR    1.675367    1.664689    1.753269    1.735387   \n",
       "13              Belgium  BEL   41.826680   40.069733   36.180079   33.563478   \n",
       "14               Belize  BLZ    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "          1994        1995        1996        1997  ...        2010  \\\n",
       "0     0.269835    0.205073    0.161310    0.119023  ...    0.329973   \n",
       "1     2.150592    1.284432    1.443130    1.537015  ...    1.099877   \n",
       "2     0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "3     0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "4     3.631131    3.278262    3.042341    2.907947  ...    3.664644   \n",
       "5     0.089702    0.051080    0.040175    0.029270  ...    0.005791   \n",
       "6   157.663172  164.275304  175.733781  180.658842  ...  193.453158   \n",
       "7     9.760491   11.893954   12.516650   12.795775  ...   12.262878   \n",
       "8     0.002359    0.014154    0.004718    0.007304  ...    0.017598   \n",
       "9     0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "10    0.475294    0.517749    0.612108    0.893869  ...    4.564487   \n",
       "11    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "12    1.537446    1.703351    1.748451    1.571995  ...    0.440235   \n",
       "13   36.907566   35.683791   33.237015   30.462139  ...   13.256519   \n",
       "14    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "\n",
       "          2011        2012        2013        2014        2015        2016  \\\n",
       "0     0.309336    0.277316    0.246716    0.311598    0.264177    0.205667   \n",
       "1     1.407936    1.388799    0.982267    0.833787    0.513685    0.396965   \n",
       "2     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4     3.937608    4.320512    4.357923    4.120342    3.856025    3.725291   \n",
       "5     0.007508    0.006603    0.003152    0.002484    0.002798    0.002849   \n",
       "6   184.804494  180.995687  168.465633  160.055324  167.850923  166.152335   \n",
       "7    12.373503   11.797346   12.090293   11.263249   12.029014   11.297731   \n",
       "8     0.013336    0.013880    0.012824    0.004828    0.000342    0.000733   \n",
       "9     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "10    4.677082    4.721276    4.856450    4.966350    7.455797    6.574876   \n",
       "11    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "12    0.492009    1.157398    1.573173    2.003347    1.785506    1.534337   \n",
       "13   12.704695   11.926863   12.603332   11.299655   10.555315    9.940550   \n",
       "14    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "          2017        2018        2019  \n",
       "0     0.204719    0.204280    0.234532  \n",
       "1     0.410189    0.232647    0.352335  \n",
       "2     0.000000    0.000000    0.000000  \n",
       "3     0.000000    0.000000    0.000000  \n",
       "4     3.656726    3.053126    1.974290  \n",
       "5     0.003707    0.004417    0.011523  \n",
       "6   160.700259  146.703499  141.675568  \n",
       "7    11.916427   10.410354   11.069428  \n",
       "8     0.006178    0.005768    0.029498  \n",
       "9     0.000000    0.000000    0.000000  \n",
       "10    7.867665   10.029381   16.538289  \n",
       "11    0.000000    0.000000    0.000000  \n",
       "12    1.630996    1.625882    1.776002  \n",
       "13    9.656882    9.914315   10.184480  \n",
       "14    0.000000    0.000000    0.000000  \n",
       "\n",
       "[15 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNimpute(df_list[0].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter/Extra-polation method with added noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shashankasubrahmanya/missing-data-imputation-using-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(temp):\n",
    "    temp = temp.drop(columns=['Country','Code'])\n",
    "    temp = temp.transpose()\n",
    "    temp = temp.replace('', np.NaN)\n",
    "    temp = temp.replace('--', np.NaN)\n",
    "    return temp\n",
    "\n",
    "#randomly impute missing values by sampling from original \n",
    "np.random.seed(42)\n",
    "def random_imputation(df, df_imp, feature):\n",
    "    number_missing = df[feature].isnull().sum()\n",
    "    observed_values = df.loc[df[feature].notnull(), feature]\n",
    "    df_imp.loc[df[feature].isnull(), feature] = np.random.choice(observed_values, number_missing, replace = True)\n",
    "    \n",
    "    return df_imp[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StochasticRegression(dataframe):    \n",
    "    df = clean_df(dataframe.copy())\n",
    "    df.columns = df.columns.map(str)\n",
    "    missing_columns = df.columns\n",
    "\n",
    "    for feature in missing_columns:\n",
    "        df[feature + '_imp'] = df[feature]\n",
    "        df = random_imputation(df, feature)\n",
    "\n",
    "    random_data = pd.DataFrame(columns = [\"Ran\" + name for name in missing_columns])\n",
    "\n",
    "    for feature in missing_columns:\n",
    "\n",
    "        random_data[\"Ran\" + feature] = df[feature + '_imp']\n",
    "        parameters = list(set(df.columns) - set(missing_columns) - {feature + '_imp'})\n",
    "        \n",
    "        model = linear_model.LinearRegression()\n",
    "        model.fit(X = df[parameters], y = df[feature + '_imp'])\n",
    "        if feature == '5':\n",
    "            print(random_data[\"Ran\" + feature])\n",
    "        #Standard Error of the regression estimates is equal to std() of the errors of each estimates\n",
    "        predict = model.predict(df[parameters])\n",
    "        std_error = (predict[df[feature].notnull()] - df.loc[df[feature].notnull(), feature + '_imp'].astype(float)).std()\n",
    "\n",
    "\n",
    "        random_predict = np.random.normal(size = df[feature].shape[0], \n",
    "                                          loc = predict, \n",
    "                                          scale = std_error)\n",
    "        random_data.loc[(df[feature].isnull()) & (random_predict > 0), \"Ran\" + feature] = random_predict[(df[feature].isnull()) & \n",
    "                                                                                (random_predict > 0)]\n",
    "    \n",
    "    random_data = random_data.transpose()\n",
    "    random_data.reset_index(drop=True, inplace=True)\n",
    "    random_data.insert(0,'c1',dataframe.Country)\n",
    "    random_data.insert(1,'c2',dataframe.Code)\n",
    "    random_data.columns = dataframe.columns\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinReg_imp(dataframe):\n",
    "    df = clean_df(dataframe.copy())\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if df[feature].isnull().sum() == 0: # break if nothing to impute\n",
    "            continue\n",
    "        #train on available data, then predict missing data\n",
    "        model = linear_model.LinearRegression()\n",
    "        X = df[feature][df[feature].notnull()].index\n",
    "        X = np.array(X).reshape(-1,1)\n",
    "        y = df[feature][df[feature].notnull()]\n",
    "        model.fit(X, y)\n",
    "\n",
    "\n",
    "        y_missing = df[feature][df[feature].isnull()].index\n",
    "        y_missing = np.array(y_missing).reshape(-1,1)\n",
    "        y_predicted = model.predict(y_missing)\n",
    "\n",
    "        #Standard Error of the regression estimates is equal to std() of the errors of each estimates\n",
    "        df.loc[df[feature].isnull(),feature] = y_predicted\n",
    "\n",
    "    temp = df.transpose()\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    temp.insert(0,'c1',dataframe.Country)\n",
    "    temp.insert(1,'c2',dataframe.Code)\n",
    "    temp.columns = dataframe.columns\n",
    "\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USing n-th degree polynomial regression\n",
    "def PolyReg_imp(dataframe, poly_degrees):\n",
    "    df = clean_df(dataframe.copy())\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if df[feature].isnull().sum() == 0: # break if nothing to impute\n",
    "            continue\n",
    "        #train on available data, then predict missing data\n",
    "        X = df[feature][df[feature].notnull()].index\n",
    "        X = np.array(X).reshape(-1,1)\n",
    "        y = df[feature][df[feature].notnull()]\n",
    "\n",
    "        poly = PolynomialFeatures(degree = poly_degrees)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        poly.fit(X_poly, y)\n",
    "        lin2 = linear_model.LinearRegression()\n",
    "        lin2.fit(X_poly, y)\n",
    "\n",
    "\n",
    "        y_missing = df[feature][df[feature].isnull()].index\n",
    "        y_missing = np.array(y_missing).reshape(-1,1)\n",
    "\n",
    "        X_polytest = poly.fit_transform(y_missing)\n",
    "        y_predicted = lin2.predict(X_polytest)\n",
    "        #Standard Error of the regression estimates is equal to std() of the errors of each estimates\n",
    "        df.loc[df[feature].isnull(),feature] = y_predicted \n",
    "    \n",
    "    temp = df.transpose()\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    temp.insert(0,'c1',dataframe.Country)\n",
    "    temp.insert(1,'c2',dataframe.Code)\n",
    "    temp.columns = dataframe.columns\n",
    "\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.05352591716192"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_df(df_list[0].copy())\n",
    "\n",
    "feature = 5\n",
    "model = linear_model.LinearRegression()\n",
    "X = df[feature][df[feature].notnull()].index\n",
    "X = np.array(X).reshape(-1,1)\n",
    "y = df[feature][df[feature].notnull()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "error = np.abs(y_test.astype(np.float) - y_pred)/y_test.astype(np.float)\n",
    "error.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.979945238712594"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "poly.fit(X_poly, y_train)\n",
    "lin2 = linear_model.LinearRegression()\n",
    "lin2.fit(X_poly, y_train)\n",
    "\n",
    "X_polytest = poly.fit_transform(X_test)\n",
    "y_pred = lin2.predict(X_polytest)\n",
    "error = np.abs(y_test.astype(np.float) - y_pred)/y_test.astype(np.float)\n",
    "error.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990            NaN\n",
       "1991            NaN\n",
       "1992    0.351333388\n",
       "1993    0.220517767\n",
       "1994    0.089702145\n",
       "1995    0.051080392\n",
       "1996     0.04017517\n",
       "1997    0.029269948\n",
       "1998    0.018364726\n",
       "1999    0.012736337\n",
       "2000     0.00607375\n",
       "2001    0.004687995\n",
       "2002    0.004485106\n",
       "2003     0.00680737\n",
       "2004    0.003953347\n",
       "2005    0.001729256\n",
       "2006    0.002788238\n",
       "2007    0.006802404\n",
       "2008    0.006249242\n",
       "2009    0.000892037\n",
       "2010    0.005790765\n",
       "2011    0.007507562\n",
       "2012    0.006603066\n",
       "2013    0.003152399\n",
       "2014     0.00248405\n",
       "2015    0.002797653\n",
       "2016     0.00284884\n",
       "2017    0.003707182\n",
       "2018    0.004416816\n",
       "2019    0.011522965\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors = 3)\n",
    "#temp = pd.DataFrame(imputer.fit_transform(df))\n",
    "df[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = df_list[0].isnull().sum(axis = 0)\n",
    "xx = xx[xx>0]\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    df_list[i].to_csv(df_names[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-9964ef898310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;34m'.csv'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_KNN'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "df_list[0].to_csv(df_names[0] - '.csv' + '_KNN' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
